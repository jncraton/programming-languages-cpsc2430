Lexing
======

Definition
----------

> In computer science, lexical analysis, lexing or tokenization is the process of converting a sequence of characters (such as in a computer program or web page) into a sequence of tokens 

Tokens
------

Commonly stored as (name, value) tuples. Example:

```python
my_variable = 17
```

Becomes:

```
(identifier, "my_variable")
(operator, "=")
(integer, 17)
```

Calculator Example
------------------

Supported operations
--------------------

- `1 + 2` = 3
- `4 - 2` = 2
- `2 * 3` = 6
- `8 / 4` = 2

Goal
----

- Scan a string such as "1 + 2 * 3" and create a list of (type, value) tuples:

```python
(number, 1)
(operator, +)
(number, 2)
(operator, *)
(number, 3)
```

Simple Lexer in Python
----------------------

```python
import sys
import re

for value in sys.argv[1].split():
    if re.match('\d+', value):
        name = 'number'
    elif re.match('[\+\-\*\/]', value):
        name = 'operator'
    else:
        raise ValueError(f'Invalid token: {value}')

    print(f'({name}, {value})')
```
